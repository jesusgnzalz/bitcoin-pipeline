{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Información de train.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5425024 entries, 0 to 5425023\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   Open    float64\n",
      " 1   High    float64\n",
      " 2   Low     float64\n",
      " 3   Volume  float64\n",
      " 4   Close   float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 206.9 MB\n",
      "None\n",
      "\n",
      "🔹 Información de test.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1356257 entries, 0 to 1356256\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   Open    1356257 non-null  float64\n",
      " 1   High    1356257 non-null  float64\n",
      " 2   Low     1356257 non-null  float64\n",
      " 3   Volume  1356257 non-null  float64\n",
      " 4   Close   1356257 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 51.7 MB\n",
      "None\n",
      "\n",
      "🔹 Información de historical.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6781281 entries, 0 to 6781280\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   Timestamp  float64\n",
      " 1   Open       float64\n",
      " 2   High       float64\n",
      " 3   Low        float64\n",
      " 4   Close      float64\n",
      " 5   Volume     float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 310.4 MB\n",
      "None\n",
      "\n",
      "🔹 Columnas en train.csv: ['Open', 'High', 'Low', 'Volume', 'Close']\n",
      "\n",
      "🔹 Columnas en test.csv: ['Open', 'High', 'Low', 'Volume', 'Close']\n",
      "\n",
      "🔹 Columnas en historical.csv: ['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume']\n",
      "\n",
      "🔹 Primeras filas de train.csv\n",
      "   Open  High   Low  Volume  Close\n",
      "0  4.58  4.58  4.58     0.0   4.58\n",
      "1  4.58  4.58  4.58     0.0   4.58\n",
      "2  4.58  4.58  4.58     0.0   4.58\n",
      "3  4.58  4.58  4.58     0.0   4.58\n",
      "4  4.58  4.58  4.58     0.0   4.58\n",
      "\n",
      "🔹 Primeras filas de test.csv\n",
      "       Open      High       Low    Volume     Close\n",
      "0  40572.83  40576.67  40569.59  1.015760  40569.59\n",
      "1  40569.59  40584.55  40566.58  0.009498  40584.55\n",
      "2  40564.78  40564.78  40564.78  0.015980  40564.78\n",
      "3  40568.76  40568.76  40541.15  0.204250  40544.74\n",
      "4  40540.29  40555.91  40540.29  0.004410  40551.74\n",
      "\n",
      "🔹 Primeras filas de historical.csv\n",
      "      Timestamp  Open  High   Low  Close  Volume\n",
      "0  1.325412e+09  4.58  4.58  4.58   4.58     0.0\n",
      "1  1.325412e+09  4.58  4.58  4.58   4.58     0.0\n",
      "2  1.325412e+09  4.58  4.58  4.58   4.58     0.0\n",
      "3  1.325412e+09  4.58  4.58  4.58   4.58     0.0\n",
      "4  1.325412e+09  4.58  4.58  4.58   4.58     0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Definir las rutas de los archivos en tu PC\n",
    "data_path = \"C:/Users/Jesus/Documents/DS_Online_Octubre24_Exercises/05_Deep_Learning/Sprint_17/Team_Challenge/bitcoin-pipeline/src/data\"\n",
    "train_path = f\"{data_path}/bitcoin_train.csv\"\n",
    "test_path = f\"{data_path}/bitcoin_test.csv\"\n",
    "historical_path = f\"{data_path}/bitcoin_historical_data.csv\"\n",
    "\n",
    "# Cargar datasets\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "df_historical = pd.read_csv(historical_path)\n",
    "\n",
    "# Mostrar información de los datasets\n",
    "print(\"\\n🔹 Información de train.csv\")\n",
    "print(df_train.info())\n",
    "\n",
    "print(\"\\n🔹 Información de test.csv\")\n",
    "print(df_test.info())\n",
    "\n",
    "print(\"\\n🔹 Información de historical.csv\")\n",
    "print(df_historical.info())\n",
    "\n",
    "# Mostrar nombres de las columnas\n",
    "print(\"\\n🔹 Columnas en train.csv:\", df_train.columns.tolist())\n",
    "print(\"\\n🔹 Columnas en test.csv:\", df_test.columns.tolist())\n",
    "print(\"\\n🔹 Columnas en historical.csv:\", df_historical.columns.tolist())\n",
    "\n",
    "# Mostrar las primeras filas de cada dataset\n",
    "print(\"\\n🔹 Primeras filas de train.csv\")\n",
    "print(df_train.head())\n",
    "\n",
    "print(\"\\n🔹 Primeras filas de test.csv\")\n",
    "print(df_test.head())\n",
    "\n",
    "print(\"\\n🔹 Primeras filas de historical.csv\")\n",
    "print(df_historical.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Columnas en df_train: ['Open', 'High', 'Low', 'Volume']\n",
      "🔹 Columnas en df_test: ['Open', 'High', 'Low', 'Volume']\n",
      "🔹 Columnas en df_historical: ['Timestamp', 'Open', 'High', 'Low', 'Close', 'Volume']\n"
     ]
    }
   ],
   "source": [
    "print(\"🔹 Columnas en df_train:\", df_train.columns.tolist())\n",
    "print(\"🔹 Columnas en df_test:\", df_test.columns.tolist())\n",
    "print(\"🔹 Columnas en df_historical:\", df_historical.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Archivos `bitcoin_train.csv` y `bitcoin_test.csv` regenerados correctamente con la columna 'Close'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definir la ruta del dataset original\n",
    "data_path = \"C:/Users/Jesus/Documents/DS_Online_Octubre24_Exercises/05_Deep_Learning/Sprint_17/Team_Challenge/bitcoin-pipeline/src/data\"\n",
    "historical_path = f\"{data_path}/bitcoin_historical_data.csv\"\n",
    "\n",
    "# Cargar el dataset original\n",
    "df = pd.read_csv(historical_path)\n",
    "\n",
    "# Convertir la columna Timestamp a formato datetime\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='s')\n",
    "df.set_index('Timestamp', inplace=True)\n",
    "\n",
    "# Asegurar que la columna 'Close' existe\n",
    "if 'Close' not in df.columns:\n",
    "    raise ValueError(\"❌ La columna 'Close' no está en los datos. Revisa el dataset original.\")\n",
    "\n",
    "# Separar características (X) y variable objetivo (y)\n",
    "X = df.drop(columns=['Close'])  # Todas las columnas excepto Close\n",
    "y = df['Close']  # Precio de cierre\n",
    "\n",
    "# Dividir en train/test (80% - 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Volver a crear los DataFrames de train y test con la columna `Close` incluida\n",
    "df_train = X_train.copy()\n",
    "df_train['Close'] = y_train  # Agregar la columna objetivo\n",
    "\n",
    "df_test = X_test.copy()\n",
    "df_test['Close'] = y_test  # Agregar la columna objetivo\n",
    "\n",
    "# Guardar los nuevos archivos CSV\n",
    "train_file = f\"{data_path}/bitcoin_train.csv\"\n",
    "test_file = f\"{data_path}/bitcoin_test.csv\"\n",
    "\n",
    "df_train.to_csv(train_file, index=False)\n",
    "df_test.to_csv(test_file, index=False)\n",
    "\n",
    "print(\"\\n✅ Archivos `bitcoin_train.csv` y `bitcoin_test.csv` regenerados correctamente con la columna 'Close'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Columnas en df_train: ['Open', 'High', 'Low', 'Volume', 'Close']\n",
      "\n",
      "🔹 Columnas en df_test: ['Open', 'High', 'Low', 'Volume', 'Close']\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(train_file)\n",
    "df_test = pd.read_csv(test_file)\n",
    "\n",
    "print(\"\\n🔹 Columnas en df_train:\", df_train.columns.tolist())\n",
    "print(\"\\n🔹 Columnas en df_test:\", df_test.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Primeras filas del dataset de entrenamiento:\n",
      "   Open  High   Low  Volume  Close\n",
      "0  4.58  4.58  4.58     0.0   4.58\n",
      "1  4.58  4.58  4.58     0.0   4.58\n",
      "2  4.58  4.58  4.58     0.0   4.58\n",
      "3  4.58  4.58  4.58     0.0   4.58\n",
      "4  4.58  4.58  4.58     0.0   4.58\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Definir rutas de los archivos\n",
    "data_path = \"C:/Users/Jesus/Documents/DS_Online_Octubre24_Exercises/05_Deep_Learning/Sprint_17/Team_Challenge/bitcoin-pipeline/src/data\"\n",
    "train_file = os.path.join(data_path, \"bitcoin_train.csv\")\n",
    "test_file = os.path.join(data_path, \"bitcoin_test.csv\")\n",
    "\n",
    "# Cargar los datos procesados\n",
    "df_train = pd.read_csv(train_file)\n",
    "df_test = pd.read_csv(test_file)\n",
    "\n",
    "# Ver las primeras filas para verificar estructura\n",
    "print(\"🔹 Primeras filas del dataset de entrenamiento:\")\n",
    "print(df_train.head())\n",
    "\n",
    "# Selección de características y target\n",
    "X_train = df_train.drop(columns=['Close'])  # 'Close' es la variable objetivo\n",
    "y_train = df_train['Close']\n",
    "\n",
    "X_test = df_test.drop(columns=['Close'])\n",
    "y_test = df_test['Close']\n",
    "\n",
    "# Identificar columnas numéricas y categóricas\n",
    "num_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_features = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Crear transformadores para preprocesamiento\n",
    "num_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Crear preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Definir el pipeline sin PCA\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Entrenar el pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n✅ Pipeline entrenado con éxito.\")\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model_path = \"C:/Users/Jesus/Documents/DS_Online_Octubre24_Exercises/05_Deep_Learning/Sprint_17/Team_Challenge/bitcoin-pipeline/src/models/bitcoin_pipeline.pkl\"\n",
    "joblib.dump(pipeline, model_path)\n",
    "\n",
    "print(f\"\\n✅ Modelo guardado en: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Definir rutas\n",
    "data_path = \"C:/Users/Jesus/Documents/DS_Online_Octubre24_Exercises/05_Deep_Learning/Sprint_17/Team_Challenge/bitcoin-pipeline/src/data\"\n",
    "model_dir = \"C:/Users/Jesus/Documents/DS_Online_Octubre24_Exercises/05_Deep_Learning/Sprint_17/Team_Challenge/bitcoin-pipeline/src/models\"\n",
    "model_path = os.path.join(model_dir, \"bitcoin_pipeline.pkl\")\n",
    "\n",
    "# Crear la carpeta models si no existe\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "# Cargar los datos de entrenamiento\n",
    "train_file = os.path.join(data_path, \"bitcoin_train.csv\")\n",
    "df_train = pd.read_csv(train_file)\n",
    "\n",
    "# Seleccionar características y variable objetivo\n",
    "X_train = df_train.drop(columns=['Close'])\n",
    "y_train = df_train['Close']\n",
    "\n",
    "# Identificar columnas numéricas y categóricas\n",
    "num_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_features = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Crear transformadores para preprocesamiento\n",
    "num_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Crear preprocesador\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_transformer, num_features),\n",
    "    ('cat', cat_transformer, cat_features)\n",
    "])\n",
    "\n",
    "# Definir el pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Entrenar el pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Guardar el modelo\n",
    "joblib.dump(pipeline, model_path)\n",
    "\n",
    "print(f\"\\n✅ Modelo guardado en: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando el entrenamiento del modelo...\n",
      "\n",
      "Archivo de entrenamiento encontrado: C:/Users/Jesus/Documents/DS_Online_Octubre24_Exercises/05_Deep_Learning/Sprint_17/Team_Challenge/bitcoin-pipeline/src/data/bitcoin_train_reduced.csv\n",
      "\n",
      "Tamaño del dataset reducido: (1000, 5)\n",
      "\n",
      "Tamaño de los datos de entrenamiento: (1000, 4)\n",
      "\n",
      "Columnas numéricas: ['Open', 'High', 'Low', 'Volume']\n",
      "\n",
      "Columnas categóricas: []\n",
      "\n",
      "Transformaciones de datos listas.\n",
      "\n",
      "Iniciando el entrenamiento...\n",
      "\n",
      "Entrenamiento completado.\n",
      "\n",
      "Modelo guardado correctamente en: C:/Users/Jesus/Documents/DS_Online_Octubre24_Exercises/05_Deep_Learning/Sprint_17/Team_Challenge/bitcoin-pipeline/src/models\\bitcoin_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print(\"\\nIniciando el entrenamiento del modelo...\")\n",
    "\n",
    "# Ruta del dataset reducido\n",
    "train_file = \"C:/Users/Jesus/Documents/DS_Online_Octubre24_Exercises/05_Deep_Learning/Sprint_17/Team_Challenge/bitcoin-pipeline/src/data/bitcoin_train_reduced.csv\"\n",
    "\n",
    "# Ruta donde se guardará el modelo\n",
    "model_dir = \"C:/Users/Jesus/Documents/DS_Online_Octubre24_Exercises/05_Deep_Learning/Sprint_17/Team_Challenge/bitcoin-pipeline/src/models\"\n",
    "model_path = os.path.join(model_dir, \"bitcoin_pipeline.pkl\")\n",
    "\n",
    "# Crear la carpeta models si no existe\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    print(\"\\nCarpeta creada:\", model_dir)\n",
    "\n",
    "# Verificar si el dataset reducido existe\n",
    "if not os.path.exists(train_file):\n",
    "    raise FileNotFoundError(\"\\nNo se encontró el archivo:\", train_file)\n",
    "\n",
    "print(\"\\nArchivo de entrenamiento encontrado:\", train_file)\n",
    "\n",
    "# Cargar los datos reducidos\n",
    "df_train = pd.read_csv(train_file)\n",
    "\n",
    "print(\"\\nTamaño del dataset reducido:\", df_train.shape)\n",
    "\n",
    "# Seleccionar características y variable objetivo\n",
    "X_train = df_train.drop(columns=['Close'])\n",
    "y_train = df_train['Close']\n",
    "\n",
    "print(\"\\nTamaño de los datos de entrenamiento:\", X_train.shape)\n",
    "\n",
    "# Identificar columnas numéricas y categóricas\n",
    "num_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_features = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(\"\\nColumnas numéricas:\", list(num_features))\n",
    "print(\"\\nColumnas categóricas:\", list(cat_features))\n",
    "\n",
    "# Crear transformadores para preprocesamiento\n",
    "num_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Crear preprocesador\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_transformer, num_features),\n",
    "    ('cat', cat_transformer, cat_features)\n",
    "])\n",
    "\n",
    "print(\"\\nTransformaciones de datos listas.\")\n",
    "\n",
    "# Definir el pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=5, max_depth=3, random_state=42))  # Parámetros reducidos para entrenar rápido\n",
    "])\n",
    "\n",
    "print(\"\\nIniciando el entrenamiento...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"\\nEntrenamiento completado.\")\n",
    "\n",
    "# Guardar el modelo\n",
    "joblib.dump(pipeline, model_path)\n",
    "\n",
    "print(\"\\nModelo guardado correctamente en:\", model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
